{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnatiusEzeani/spatial_narratives_workshop/blob/main/spatial_narrative_demo1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUojVOiIhoEv"
      },
      "source": [
        "# **Extracting Spatial Entities from text (1)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ0kCbYUh4gu"
      },
      "source": [
        "## Task Description:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcfL-sEdGCIm"
      },
      "source": [
        "![](https://raw.githubusercontent.com/SpaceTimeNarratives/demo/main/img/from_penrith_both.png)\n",
        "\n",
        "Assuming we know nothing about the geography of the place(s) described by the corpus, what can we learn about it. In particular:\n",
        "* **What places are there?** These can be:\n",
        " * `Toponyms` (*Keswick*, *Pooley Bridge*, *the River Lowther*)\n",
        " * `Geographical features` (*the town*, *a hill*, *the road*)\n",
        " * `Locative adverbs` (*above*, *north-of*, *eastwards*, *here*, *there*)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Rule-Based Method\n",
        "Our aim in these exercises is to extract and mark up these spatial elements in text as shown. We will walk through building the foundations of a baseline extraction tool for *placenames*, *geographic feature nouns*, *locative adverbs* and any other entity category for which we have a list.\n",
        "\n",
        "This notebook focuses on developing a **rule based** method for extracting entities in a lists using regular expression."
      ],
      "metadata": {
        "id": "lZQex_MqCF6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Downloading the workshop materials**\n",
        "Let's download (clone) the resources for the workshop from the [Spatial Narratives Demo](https://github.com/SpaceTimeNarratives/demo)  GitHub repository."
      ],
      "metadata": {
        "id": "VQzZg_4jQ9Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SpaceTimeNarratives/demo.git"
      ],
      "metadata": {
        "id": "16hV3t2_K-Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<img src=\"https://raw.githubusercontent.com/SpaceTimeNarratives/demo/main/img/file_structure.png\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "The `spatial_narratives_workshop` directory contains an example file `example_text.txt`. Our aim is to read file and display the text as well as identify all the place names mentioned in the text.\n",
        "\n",
        "### Changing into the working directory\n",
        "Everything we need for this exercise can be found in the working directory (or folder) named *demo*. We will use the `os` (operating system) library which contains all the useful functions we may need to manage our folders and files programmatically. \n",
        "\n",
        "Here we use the `chdir()` (change directory) function to get into our working directory and list the contents of our directory using the `listdir()` \n",
        "\n",
        "Type (or copy and paste) the code below in the next cell and run.\n",
        "\n",
        "```python\n",
        "import os\n",
        "os.chdir('demo/')\n",
        "os.listdir()\n",
        "```"
      ],
      "metadata": {
        "id": "-gHbsXiiSIGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Type or paste the command below:\n"
      ],
      "metadata": {
        "id": "cSzKcVhYR-1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing the example text\n",
        "Our working folder contains the example text file *example_text.txt* which you can double-click on to read it's contents on another pane.\n",
        "\n",
        "However we can programmatically read it into a *variable* named `example_text` by using the `open` command. A variable is basically a named container for storing values that vary (of course..) while the program runs and reusing them when we need to.\n",
        "\n",
        "*Type copy and paste the command in the code cell below:* \n",
        "\n",
        "```python\n",
        "example_text =  open('example_text.txt').read()\n",
        "example_text\n",
        "```"
      ],
      "metadata": {
        "id": "vLZdA28eViwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Type or paste the command below:\n"
      ],
      "metadata": {
        "id": "S4AuLs0uUti2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Rule-Based Placename Extraction**\n",
        "In this section, we will apply a rule-based approach that uses regular expression (regex) and a combination of other techniques to extract and visualize place names from text. "
      ],
      "metadata": {
        "id": "8wf3pdzkWFS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extracting placenames\n",
        "Here we think about a way to extract a known place name (e.g. `Penrith`) from the text. We will use the Python library `re` (regular expression) to build search patterns to look for in the text.\n",
        "\n",
        "So let's say we defining called function (or method) called `extract_placename(text, placename)` such that we can give it some *text* and a list of *placenames* and it returns all occurences of each of the placename in the text.\n",
        "\n",
        "The code below defines the `extract_placename(text, placename)` function.\n"
      ],
      "metadata": {
        "id": "LCQBR8lJTAii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_placenames(text, placenames):\n",
        "  sorted(set(placenames), key=lambda x:len(x), reverse=True)\n",
        "  extracted_placenames = {}\n",
        "  for name in placenames:\n",
        "    for match in re.finditer(f'{name}[\\.,\\s\\n;:]', text):\n",
        "      extracted_placenames[match.start()]=text[match.start():match.end()-1]\n",
        "  return {i:extracted_placenames[i] for i in sorted(extracted_placenames.keys())}"
      ],
      "metadata": {
        "id": "-w51uoIkdtdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "place_names = ['Carleton Hall', 'Dunmallet', 'Eamont', 'Eamont Bridge', \n",
        "               'Hallen Fell',  'Penrith', 'Pooley Bridge', 'Shap', 'ULLESWATER',\n",
        "               'Ulleswater']\n",
        "\n",
        "extracted_place_names = extract_placenames(example_text, place_names)\n",
        "extracted_place_names"
      ],
      "metadata": {
        "id": "HQ4dmJwUgoyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above output (`{5: 'Penrith', 31: 'Pooley Bridge', ...}`) is a dictionary with the `start: placename` entries where `start` is the starting character index (or position) of the `placename` in the order they are found in text. \n",
        "\n",
        "For example `Penrith` was the first placename found and the started from character index 5. `Pooley Bridge` appeared thrice in the text with starting indexes `31`, `450` and `856`. By the way the first character is in position `0` (not `1`).\n",
        "\n",
        "You may observe that it got all occurences of the placenames on our list. But there are other placenames in the text such as `King Arthur's Round Table`, `Lowther Castle`, `Martindale`, `Mayborough`, `Patterdale`. We will come back to this later.\n",
        "\n"
      ],
      "metadata": {
        "id": "O07te8A0ehBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Visualizing the outputs**\n",
        "It is often a good idea to present a graphic representation of our outputs for better visualization and understanding of how our process works.\n",
        "\n",
        "Using the `HTML` function inside the `IPython` library's `display` package, we define functions that display the HTML format of the visualisation of the extracted place names in the text."
      ],
      "metadata": {
        "id": "mu3VPj2cqYid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Visualizing the plain text**\n",
        "\n",
        "Visualizing the untagged example text is easy. We simply pass the `example_text` variable to the I"
      ],
      "metadata": {
        "id": "-eKIFfzsaXRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "HTML(example_text)"
      ],
      "metadata": {
        "id": "fw3i7Od_sH1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Visualizing the extracted place names**\n",
        "This is a little more challenging but will follow the same principle. Having extracted the place names, we can define functions that will help us 'mark-up' or highlight the extracted place names from the plain text based on their starting index positions and spans so we can visualize it in HTML format.\n",
        "\n",
        "Let's call the first function `get_tagged_list()`. It will parse the text with dictionary of extracted place names and identify spans that will be tagged as place names in the text. Its output is a list of tuples containing text spans and tags (either `PLNAME` or `None`)"
      ],
      "metadata": {
        "id": "tgbwfPbh4TWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract all known place name in a list\n",
        "def get_tagged_list(text, ext_pl_names):\n",
        "  begin, tokens_tags = 0, []\n",
        "  for start, plname in ext_pl_names.items():\n",
        "    length, ent, tag = len(plname), plname, 'PLNAME'\n",
        "    if begin <= start:\n",
        "      tokens_tags.append((text[begin:start], None))\n",
        "      tokens_tags.append((text[start:start+length], tag))\n",
        "      begin = start+length\n",
        "  tokens_tags.append((text[begin:], None)) #add the last untagged chunk\n",
        "  return tokens_tags\n",
        "\n",
        "# get_tagged_list(example_text, extracted_place_names)"
      ],
      "metadata": {
        "id": "Wb0VTn717w7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second function `mark_up`, which takes a `token` (actually a span of characters) and a tag (i.e. `PL-NAME` for place name) basically marks up or highlights any piece of text with a given background colour in HTML format."
      ],
      "metadata": {
        "id": "MOHEigcrFvFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mark_up(token, tag=None):\n",
        "  if tag:\n",
        "    begin_bkgr = f'<bgr class=\"entity\" style=\"background: #feca74 ; padding: 0.1em 0.1em; margin: 0 0.15em; border-radius: 0.23em;\">'\n",
        "    end_bkgr = '\\n</bgr>'\n",
        "    begin_span = '<span style=\"font-size: 0.8em; font-weight: bold; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n",
        "    end_span = '\\n</span>'\n",
        "    return f\"{begin_bkgr}{token}{begin_span}{tag}{end_span}{end_bkgr}\"\n",
        "  return f\"{token}\"\n",
        "# HTML(mark_up('Penrith', tag='PLNAME'))"
      ],
      "metadata": {
        "id": "UXSRDRNhFP5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we piece everything together with the function `generate_html()` which does exactly that by marking up the output of the `get_tagged_list()` with the `mark_up()` function."
      ],
      "metadata": {
        "id": "glVyOK7IIoxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate html formatted text \n",
        "def visualize(token_tag_list):\n",
        "  start_div = f'<div class=\"entities\" style=\"line-height: 2.0; direction: ltr\">'\n",
        "  end_div = '\\n</div>'\n",
        "  html = start_div\n",
        "  for token, tag in token_tag_list:\n",
        "    html += mark_up(token,tag)\n",
        "  html += end_div\n",
        "  return HTML(html)\n",
        "\n",
        "visualize(get_tagged_list(example_text, extracted_place_names))"
      ],
      "metadata": {
        "id": "UWpp-0NoFvrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Extracting with a gazetteer**\n",
        "Our previous examples so far is only able to extract and visualise a few place names. Obviously, for a chance to be able to extract all the place names in the text, we will need a more comprehensive list.\n",
        "\n",
        "So for this task, we will apply the techniques and processes defined above with a list of the Lake District place names from the gazetteer created by [Source]() to identify and extract mentions of the place names in the same text."
      ],
      "metadata": {
        "id": "3_g1_U1Cn_u4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read LD placenames into a list\n",
        "ld_place_names = [name.strip() for name in open('LD_placenames.txt').readlines()]\n",
        "\n",
        "# Extract place names from the same example text \n",
        "extracted_place_names = extract_placenames(example_text, ld_place_names)\n",
        "\n",
        "# Get list of tagged entities (or placenames) and their tags\n",
        "tagged_list = get_tagged_list(example_text, extracted_place_names)\n",
        "\n",
        "visualize(tagged_list)"
      ],
      "metadata": {
        "id": "orzBT4Yhg9R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, so far our method works quite well if we have what we are looking for in the list exactly as it appears in the text. Otherwise, it may wobble a bit. \n",
        "\n",
        "A typical example in the text above <mark>Lowther</mark> and <mark>Castle</mark> separately marked instead of <mark>Lowther Castle</mark>."
      ],
      "metadata": {
        "id": "CYUW-Zq-87-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5: Extracting geographical feature nouns with list**\n",
        "To extract geographical features from a list of feature nouns (e.g. `castle`, `ridge`, `forest`, `village`, `river` etc), we will apply the same method as placenames.\n",
        "\n",
        "We will modify the `extract_placenames()` function to be more generic for all entity classes i.e. `extract_entities()`.\n",
        "\n",
        "Also, to enable us apply a new tag `GEONOUN`, let's modify the `get_tagged_list()` function to accept the tag parameter that defaults to the `PLNAME` but supports other tags."
      ],
      "metadata": {
        "id": "b4RGgDoawe91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entities(text, ent_list):\n",
        "  sorted(set(ent_list), key=lambda x:len(x), reverse=True)\n",
        "  extracted_entities = {}\n",
        "  for ent in ent_list:\n",
        "    for match in re.finditer(f' {ent}[\\.,\\s\\n;:]', text):\n",
        "      extracted_entities[match.start()+1]=text[match.start()+1:match.end()-1]\n",
        "  return {i:extracted_entities[i] for i in sorted(extracted_entities.keys())}\n",
        "\n",
        "extract_entities(example_text, place_names)"
      ],
      "metadata": {
        "id": "egwljeRaCTwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Include `tag` in the `get_tagged_list()` parameters to enable the use of other tags `tag='PLNAME'` defaults to placenames but explicit passing of other tags (e.g. `GEONOUNS`) will override it."
      ],
      "metadata": {
        "id": "X27G4MFgyshY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract all known place name in a list\n",
        "def get_tagged_list(text, entities, tag='PLNAME'):\n",
        "  begin, tokens_tags = 0, []\n",
        "  for start, ent in entities.items():\n",
        "    if begin <= start:\n",
        "      tokens_tags.append((text[begin:start], None))\n",
        "      tokens_tags.append((text[start:start+len(ent)], tag))\n",
        "      begin = start+len(ent)\n",
        "  tokens_tags.append((text[begin:], None)) #add the last untagged chunk\n",
        "  return tokens_tags\n",
        "\n",
        "# get_tagged_list(example_text, extracted_place_names)"
      ],
      "metadata": {
        "id": "pwWUgDFLBKb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need inflections and lemmas of all the words in the geo nouns list. For example, if we have `road` in the list, then we will need `roads` as well, and vice versa.\n",
        "\n",
        "So we will install the `lemminflect` library and define the `get_inflections()` function."
      ],
      "metadata": {
        "id": "PGxmR_rGz1HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lemminflect"
      ],
      "metadata": {
        "id": "GsYdojryGGB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand list with inflections and lemmas\n",
        "from lemminflect import getLemma, getInflection\n",
        "def get_inflections(names_list):\n",
        "    gf_names_inflected = []\n",
        "    for w in names_list:\n",
        "      gf_names_inflected.append(w)\n",
        "      gf_names_inflected.extend(list(getInflection(w.strip(), tag='NNS', inflect_oov=False)))\n",
        "      gf_names_inflected.extend(list(getLemma(w.strip(), 'NOUN', lemmatize_oov=False)))\n",
        "    return list(set(gf_names_inflected))"
      ],
      "metadata": {
        "id": "4Y79jODFF6fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to define a background color dictionary `BG_COLOR` for visualization so that the system can decide what colour to apply in highliting the entities of different tags in the text. \n",
        "\n",
        "Accordingly, the entity backgound in the `mark_up()` will be modified to select a color from the dictionary using the tag as the key (i.e. `BG_COLOR[tag]`)."
      ],
      "metadata": {
        "id": "NN9hJrwV0-qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BG_COLOR = {'PLNAME':'#feca74','GEONOUN': '#9cc9cc'}\n",
        "# Marking up the token for visualization\n",
        "def mark_up(token, tag=None):\n",
        "  if tag:\n",
        "    begin_bkgr = f'<bgr class=\"entity\" style=\"background: {BG_COLOR[tag]} ; padding: 0.1em 0.1em; margin: 0 0.15em; border-radius: 0.23em;\">'\n",
        "    end_bkgr = '\\n</bgr>'\n",
        "    begin_span = '<span style=\"font-size: 0.8em; font-weight: bold; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n",
        "    end_span = '\\n</span>'\n",
        "    return f\"{begin_bkgr}{token}{begin_span}{tag}{end_span}{end_bkgr}\"\n",
        "  return f\"{token}\""
      ],
      "metadata": {
        "id": "1zsXUh4N4lOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we read the geo nouns saved in `geo_feature_nouns.txt` into a list and produce the tagged list with the extracted geo nouns using the `GEONOUN` tag. "
      ],
      "metadata": {
        "id": "hVnyZJmq2OUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read LD placenames into a list\n",
        "geonouns = get_inflections([noun.strip() for noun in open('geo_feature_nouns.txt').readlines()])\n",
        "tagged_geonouns = get_tagged_list(example_text, extract_entities(example_text, geonouns), 'GEONOUN')\n",
        "visualize(tagged_geonouns)"
      ],
      "metadata": {
        "id": "kw8m_Jm28USg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: Extracting and visualising multiple entity types**"
      ],
      "metadata": {
        "id": "s2tF98RENrRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we can extract multiple entities from text, we have to modify or functions to be more generalizable. That way, we can pass any list of items of eny category that we are interested in.\n",
        "\n",
        "The `extract_entities()` function will also be rewritten to return not just the entities and their starting position but also their tags."
      ],
      "metadata": {
        "id": "l238Wj_4nqFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates a list of all tokens, tagged and untagged, for visualisation\n",
        "def extract_entities(text, ent_list, tag='PLNAME'):\n",
        "  sorted(set(ent_list), key=lambda x:len(x), reverse=True)\n",
        "  extracted_entities = {}\n",
        "  for ent in ent_list:\n",
        "    for match in re.finditer(f' {ent}[\\.,\\s\\n;:]', text):\n",
        "      # modified to return the `tag` too...\n",
        "      extracted_entities[match.start()+1]=text[match.start()+1:match.end()-1], tag\n",
        "  return {i:extracted_entities[i] for i in sorted(extracted_entities.keys())}\n",
        "\n",
        "# extract_entities(example_text, place_names)"
      ],
      "metadata": {
        "id": "dBfY8-TTnUqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, in building the tagged list of tokens for the visualizer, we need to include the tags of the entities (`PLNAME` for placenames and GEONOUN for geo feature nouns) and `None` for other tokens."
      ],
      "metadata": {
        "id": "GD__4kufOkVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates a list of all tokens, tagged and untagged, for visualisation\n",
        "def get_tagged_list(text, entities):\n",
        "  begin, tokens_tags = 0, []\n",
        "  for start, (ent, tag) in entities.items():\n",
        "    if begin <= start:\n",
        "      tokens_tags.append((text[begin:start], None))\n",
        "      tokens_tags.append((text[start:start+len(ent)], tag))\n",
        "      begin = start+len(ent)\n",
        "  tokens_tags.append((text[begin:], None)) #add the last untagged chunk\n",
        "  return tokens_tags\n",
        "\n",
        "# get_tagged_list(example_text, extracted_place_names)"
      ],
      "metadata": {
        "id": "txRLKNOhObPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need another function `merge_entities()` to combine the entities that we have extracted and their tags into a single dictionary."
      ],
      "metadata": {
        "id": "ZUtGZmlm9Wbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merging entities\n",
        "from collections import OrderedDict\n",
        "def merge_entities(first_ents, second_ents):\n",
        "  return OrderedDict(sorted({** second_ents, **first_ents}.items()))"
      ],
      "metadata": {
        "id": "PIv9ml6LJiOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try to extract, merge and visualize multiple entities (i.e. placenames and geo nouns).\n",
        "\n",
        "The code below will tag all extracted names as place names by default\n",
        "\n",
        "```python\n",
        "extracted_placenames = extract_entities(example_text, place_names)\n",
        "```\n",
        "\n",
        "However, in the code below, we have to explicitly pass `GEONOUN` to the tag parameter\n",
        "\n",
        "```python\n",
        "extracted_geonouns = extract_entities(example_text, geonouns, tag='GEONOUN')\n",
        "```"
      ],
      "metadata": {
        "id": "ldX8H-rH97MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_placenames = extract_entities(example_text, place_names)\n",
        "extracted_geonouns = extract_entities(example_text, geonouns, tag='GEONOUN')\n",
        "\n",
        "merged_entities = merge_entities(extracted_placenames, extracted_geonouns)"
      ],
      "metadata": {
        "id": "GldVd0K3M89b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of tagged entities (or placenames) and their tags\n",
        "tagged_list = get_tagged_list(example_text, merged_entities)\n",
        "visualize(tagged_list)"
      ],
      "metadata": {
        "id": "Mo3zV6uch05a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise:**\n",
        "\n",
        "The `locativeAdverbs.txt` file in the working folder contains a list of the locative adverbs (i.e *above*, *homewards*, *northbound*, *southwards* etc.\n",
        "\n",
        "**Task 1:** Use the code below to read the list into a Python variable `loc_advs`.\n",
        "\n",
        "```python\n",
        "loc_advs = [adv.split()[0] for adv in open('locativeAdverbs.txt').readlines()]\n",
        "```"
      ],
      "metadata": {
        "id": "Kgis8p2SXZ6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Type code below...\n"
      ],
      "metadata": {
        "id": "evTgsugMkTBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2:** Extract locative locative adverbs in the text using the following code.\n",
        "\n",
        "```python\n",
        "extracted_locadvs = extract_entities(example_text, loc_advs, tag='LOCADV')\n",
        "```"
      ],
      "metadata": {
        "id": "LfKDQsPrkhlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Type code below...\n"
      ],
      "metadata": {
        "id": "03t21_I0kT5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3:** Modify the background colour dictionary `BG_COLOR` to add the colour for the `LOCADV` tag.\n",
        "\n",
        "```python\n",
        "BG_COLOR = {'PLNAME':'#feca74','GEONOUN': '#9cc9cc', 'LOCADV':'#f5b5cf'}\n",
        "```"
      ],
      "metadata": {
        "id": "2JLIU8ErkpV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Type code below...\n"
      ],
      "metadata": {
        "id": "ZPm00FVLkTqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4:** Visualize the locative adverbs in text with the `visualize()` function.\n",
        "\n",
        "```python\n",
        "visualize(get_tagged_list(example_text, extracted_locadvs))\n",
        "```"
      ],
      "metadata": {
        "id": "teqcWPOZkxCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Type code below...\n"
      ],
      "metadata": {
        "id": "rSdIa-t7kTfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 5:** Use `extract_entities()`, `merge_entities()` and `visualize()` functions to extract, merger and visualize **placenames**, **geo nouns** and **locative adverbs**."
      ],
      "metadata": {
        "id": "rbfhLfFJk3sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Type code below...\n"
      ],
      "metadata": {
        "id": "wnuGtvKGkTSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Putting it all together..**"
      ],
      "metadata": {
        "id": "WifH5PM1EddJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the summary of the code that powers the rule-based extraction method in this notebook.\n",
        "\n",
        "```python\n",
        "!git clone https://github.com/SpaceTimeNarratives/demo.git\n",
        "```\n",
        "\n",
        "```python\n",
        "!pip install lemminflect\n",
        "```\n",
        "\n",
        "```python\n",
        "from IPython.display import HTML\n",
        "from collections import OrderedDict\n",
        "from lemminflect import getLemma, getInflection\n",
        "```\n",
        "\n",
        "```python\n",
        "BG_COLOR = {'PLNAME':'#feca74','GEONOUN': '#9cc9cc', 'LOCADV':'#f5b5cf'}\n",
        "```\n",
        "\n",
        "```python\n",
        "# Generates a list of all tokens, tagged and untagged, for visualisation\n",
        "def extract_entities(text, ent_list, tag='PLNAME'):\n",
        "  sorted(set(ent_list), key=lambda x:len(x), reverse=True)\n",
        "  extracted_entities = {}\n",
        "  for ent in ent_list:\n",
        "    for match in re.finditer(f' {ent}[\\.,\\s\\n;:]', text):\n",
        "      # modified to return the `tag` too...\n",
        "      extracted_entities[match.start()+1]=text[match.start()+1:match.end()-1], tag\n",
        "  return {i:extracted_entities[i] for i in sorted(extracted_entities.keys())}\n",
        "\n",
        "# Merging entities\n",
        "def merge_entities(first_ents, second_ents):\n",
        "  return OrderedDict(sorted({** second_ents, **first_ents}.items()))\n",
        "\n",
        "# Generates a list of all tokens, tagged and untagged, for visualisation\n",
        "def get_tagged_list(text, entities):\n",
        "  begin, tokens_tags = 0, []\n",
        "  for start, (ent, tag) in entities.items():\n",
        "    if begin <= start:\n",
        "      tokens_tags.append((text[begin:start], None))\n",
        "      tokens_tags.append((text[start:start+len(ent)], tag))\n",
        "      begin = start+len(ent)\n",
        "  tokens_tags.append((text[begin:], None)) #add the last untagged chunk\n",
        "  return tokens_tags\n",
        "\n",
        "# Marking up the token for visualization\n",
        "def mark_up(token, tag=None):\n",
        "  if tag:\n",
        "    begin_bkgr = f'<bgr class=\"entity\" style=\"background: {BG_COLOR[tag]}; padding: 0.05em 0.05em; margin: 0 0.15em;  border-radius: 0.55em;\">'\n",
        "    end_bkgr = '\\n</bgr>'\n",
        "    begin_span = '<span style=\"font-size: 0.8em; font-weight: bold; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">'\n",
        "    end_span = '\\n</span>'\n",
        "    return f\"{begin_bkgr}{token}{begin_span}{tag}{end_span}{end_bkgr}\"\n",
        "  return f\"{token}\"\n",
        "\n",
        "# generate html formatted text \n",
        "def visualize(token_tag_list):\n",
        "  start_div = f'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">'\n",
        "  end_div = '\\n</div>'\n",
        "  html = start_div\n",
        "  for token, tag in token_tag_list:\n",
        "    html += mark_up(token,tag)\n",
        "  html += end_div\n",
        "  return HTML(html)\n",
        "\n",
        "# Get inflections and lemmas of geo nouns\n",
        "def get_inflections(names_list):\n",
        "    gf_names_inflected = []\n",
        "    for w in names_list:\n",
        "      gf_names_inflected.append(w)\n",
        "      gf_names_inflected.extend(list(getInflection(w.strip(), tag='NNS', inflect_oov=False)))\n",
        "      gf_names_inflected.extend(list(getLemma(w.strip(), 'NOUN', lemmatize_oov=False)))\n",
        "    return list(set(gf_names_inflected))\n",
        "```"
      ],
      "metadata": {
        "id": "sgSSQ8ZxEvoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Next step...**\n"
      ],
      "metadata": {
        "id": "cXWNJZ4_l_pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Named Entity Recognition and Semantic Tagging**\n",
        "\n",
        "With the rule-based approach, we could extract the placenames, geo nouns, locative adverbs any other category of items in alist. \n",
        "\n",
        "However, it is limited in a number of ways.\n",
        "* It requires an exhaustive list of place names which is difficult to build for different types of writings.\n",
        "* Hand-crafted rules for all possible scenarios will need to be developed\n",
        "  - e.g. spelling errors, capitalizations, inflections etc.\n",
        "  - Over-lapping instances ('Eamont' vs 'Eamont Bridge')\n",
        "* It will be more difficult to extract references to time and date as well as sentiments and emotions.\n",
        "* The approach will not generalize well with other corpora\n",
        "\n",
        "In the next section, we will adapt some existing tools - a named entity recognizer and a semantic tagger to try to mitigate some of the challenges above. "
      ],
      "metadata": {
        "id": "JFuaIOmSmBCa"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VQzZg_4jQ9Ch",
        "LCQBR8lJTAii",
        "jOdjjJwFHv11",
        "vb8f7aoPsYgL",
        "Zw9jVk97R4SB",
        "1tCywxkPi1r2",
        "WwolMngoq_hs"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}