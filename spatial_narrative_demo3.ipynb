{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qN64bH1KCFARFlK-H_AzEAZzk79VBD7P","timestamp":1677265360771}],"authorship_tag":"ABX9TyOtS8V97e7eGFEMj81vdV2L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Extracting Spatial Entities from text (3)**\n","---"],"metadata":{"id":"tD4XcOgMbEAD"}},{"cell_type":"markdown","source":["## Task Description:"],"metadata":{"id":"OBVRT99NbJfk"}},{"cell_type":"markdown","source":["![](https://raw.githubusercontent.com/IgnatiusEzeani/spatial_narratives_workshop/main/img/from_penrith_tagged.png)\n","\n","Assuming we know nothing about the geography of the place(s) described by the corpus, what can we learn about it. In particular:\n","* **What places are there?** These can be:\n"," * `Toponyms` (*Keswick*, *Pooley Bridge*, *the River Lowther*)\n"," * `Geographical features` (*the town*, *a hill*, *the road*)\n"," * `Locative adverbs` (*above*, *north-of*, *eastwards*, *here*, *there*)"],"metadata":{"id":"fsibz9NbbvJi"}},{"cell_type":"markdown","source":["## Using Spacy's `EntityRuler` to build rules based extraction model\n","In **Demo 2**, we included the PyMUSAS Semantic Tagger to the rules based pipeline for spatial elements extraction from text.\n","\n","While this broadened the scope of the spactial classes we could extract, it has the problem of managing too many components within the pipeline. \n","\n","The [EntityRuler](https://spacy.io/api/entityruler) is a Spacy component that enables us to add named entities based on pattern dictionaries, which makes it easy to combine rule-based and statistical named entity recognition for even more powerful pipelines.\n","\n","In this demo, we will demonstrate how to use the EntityRuler to build a much simpler and more efficient extraction pipeline."],"metadata":{"id":"GbLU6kjtcajy"}},{"cell_type":"markdown","source":["## **Step 1: Downloading the workshop materials**\n","Let's download (clone) the resources for the workshop from the [Spatial Narrative Demo](https://github.com/SpaceTimeNarratives/demo)  GitHub repository."],"metadata":{"id":"T1pnZHuyiM4V"}},{"cell_type":"code","source":["!git clone https://github.com/SpaceTimeNarratives/demo.git"],"metadata":{"id":"5okOn8ZNPdWL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As in the previous demos, the `demo` directory contains the example file `example.txt` and everything we need for this exercise.\n","\n","Run the code below to change to the working directory `demo/` and list its content."],"metadata":{"id":"81XYg1Qkivr6"}},{"cell_type":"code","source":["# Type or paste the command below:\n","import os\n","os.chdir('demo/')"],"metadata":{"id":"H8fuWczdPg7S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Install required libraries in `requirements.txt` files."],"metadata":{"id":"oyJEqqtisrXo"}},{"cell_type":"code","source":["pip -q install -r requirements.txt"],"metadata":{"id":"FpY9Mq3T3mc5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run the code `%run functions.py` to define the required functions"],"metadata":{"id":"TN3Bpx21tc_h"}},{"cell_type":"code","source":["%run functions.py"],"metadata":{"id":"Yj0HAwESolzu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Step 2: Read the text and load the entity lists**\n","First, let's load the example text from `example.txt` into the variable `example_text`..."],"metadata":{"id":"oSFgkUXyo7Kq"}},{"cell_type":"code","source":["example_text = open('example.txt').read()"],"metadata":{"id":"YJe11jAwp2aO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the place names from `LD_placenames.txt` file. Also, ensure that each name is in *title* (i.e. starting characters are capitalised) or *upper* case. Those are thee most likely case they will have in the text."],"metadata":{"id":"6LjZ1YNjqPFj"}},{"cell_type":"code","source":["place_names = [name.strip().title().replace(\"'S\", \"'s\") for name in open('LD_placenames.txt').readlines()] #read and convert to title case \n","place_names += [name.upper() for name in place_names] #retain the upper case versions"],"metadata":{"id":"TW06e2W2qiy8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Step 3: Building the rules with `EntityRuler`**\n","Let's start by importing `spacy` for building the model"],"metadata":{"id":"DVco81Gq09lM"}},{"cell_type":"code","source":["import spacy"],"metadata":{"id":"EnPpPcAV1xah"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a blank `spacy` English model"],"metadata":{"id":"2ph1WQBlrDi9"}},{"cell_type":"code","source":["nlp = spacy.blank(\"en\")"],"metadata":{"id":"RYRyaAp04qdl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create the EntityRuler"],"metadata":{"id":"T8EAu7WW4m6C"}},{"cell_type":"code","source":["ruler = nlp.add_pipe(\"entity_ruler\")"],"metadata":{"id":"0139Gbsb4nRA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define the patterns for the `EntityRuler` by labelling all the names with the tag `PLNAME`"],"metadata":{"id":"LS52827pq6y7"}},{"cell_type":"code","source":["patterns = [{\"label\": \"PLNAME\", \"pattern\": plname} for plname in set(place_names)]\n","ruler.add_patterns(patterns)"],"metadata":{"id":"KW80mHYUq7TE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Step 4: Extracting placenames from example text**\n","Now we are ready to extract and visualize place names from text using the Spacy pipeline. Let's start by processing the text with the `nlp` pipeline. "],"metadata":{"id":"RWUSDWgC74Y9"}},{"cell_type":"code","source":["doc = nlp(example_text)"],"metadata":{"id":"omTK-5V1rECi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can look at the place names that were extracted from our example text. The code below displays `<place name> <start char index> <end char index> <label>` on each line for all place names found."],"metadata":{"id":"S0RTTIDW9uZm"}},{"cell_type":"code","source":["for ent in doc.ents:\n","    print(ent.text, ent.start_char, ent.end_char, ent.label_)"],"metadata":{"id":"_sC6SmIt89i3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's use `displacy` to render the visualization of the extracted place names. We can use our pre-defined color dictionary, `BG_COLOR` to highlight the place names in the text."],"metadata":{"id":"eQPybLNw_WQF"}},{"cell_type":"code","source":["from spacy import displacy\n","options = {'colors':BG_COLOR}\n","displacy.render(doc, style=\"ent\", jupyter=True, options=options)"],"metadata":{"id":"fL5Ei0lrrT7i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Step 5: Extracting geographic feature nouns**\n","As in the previous demos, we are also intersted in extracting other features besides the place names. In this section, we will add the goe feature nouns with an appropriate label to our `patterns` list.\n","\n","Let's start by reading the geo nouns from file and getting the lemmas and inflections. The code below shows a list of the 261 geo nouns and their inflections (`mountains`, `islands`, `pikes`, `towers`, `bays`, etc) "],"metadata":{"id":"Pk7JE0ww_5KW"}},{"cell_type":"code","source":["geonouns = get_inflections([noun.strip() for noun in open('geo_feature_nouns.txt').readlines()])"],"metadata":{"id":"BaR2Pl4jD27i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We then need to update the `patterns` list (which currently have the place names) with the geo nouns labelled as `GEONOUN`. This will require re-initialising the model with a new `EntityRuler` pipeline."],"metadata":{"id":"m7RgxIhABIxA"}},{"cell_type":"code","source":["nlp = spacy.blank(\"en\")\n","ruler = nlp.add_pipe(\"entity_ruler\")\n","patterns += [{\"label\": \"GEONOUN\", \"pattern\": noun} for noun in geonouns]\n","ruler.add_patterns(patterns)"],"metadata":{"id":"1C5Sl66sE9_c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Processing the `example_text` and visualising entities..."],"metadata":{"id":"AJeFZ09rKczE"}},{"cell_type":"code","source":["doc = nlp(example_text)\n","displacy.render(doc, style=\"ent\", jupyter=True, options=options)"],"metadata":{"id":"Axs-HIhEHv-o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## **Exercise**\n","As in the previous demos, we can include locative adverbs (i.e *above*, *homewards*, *northbound*, *southwards* etc.) in `locativeAdverbs.txt` file in the visualisation.\n","\n","**Task 1:** Use the code below to read the list into a Python variable `loc_advs`.\n","\n","```python\n","loc_advs = [adv.split()[0] for adv in open('locativeAdverbs.txt').readlines()]\n","```"],"metadata":{"id":"t4AKejixMqo5"}},{"cell_type":"code","source":["# Type code below...\n"],"metadata":{"id":"xgeuVivYREHc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Task 2:** Create a blank spacy model and add a new `EntityRuler` to the pipeline using the code below:\n","```python\n","nlp = spacy.blank(\"en\")\n","ruler = nlp.add_pipe(\"entity_ruler\")\n","```\n","\n"],"metadata":{"id":"QAClWatwQRqO"}},{"cell_type":"code","source":["# Type code below...\n"],"metadata":{"id":"x8VhyQGLMP5g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Task 3:** Update the `patterns` list to include locative locative adverbs in the text using the following code.\n","\n","```python\n","patterns += [{\"label\": \"LOCADV\", \"pattern\": adv} for adv in loc_advs]\n","ruler.add_patterns(patterns)\n","```"],"metadata":{"id":"YdYpkYFIOcP3"}},{"cell_type":"code","source":["# Type code below...\n"],"metadata":{"id":"a-OjQTLQQSA6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Task 4:** Process the example text with the new `nlp` model and visualise as done in *Step 5*."],"metadata":{"id":"9bxmVWGySRcK"}},{"cell_type":"code","source":["# Type code below...\n","doc = nlp(example_text)\n","displacy.render(doc, style=\"ent\", jupyter=True, options=options)"],"metadata":{"id":"wJruRTWaOce_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Step 6: Adding the `EntityRuler` to an existing pipeline**\n","So far, we have used a blank NLP model for our pipeline. However, we can leverage a pre-trained model by adding the `EntityRuler` to the model's pipeline. This will allow us to extract other entities not captured in our defined `patterns`.\n","\n","So instead of `nlp = spacy.blank(\"en\")` let's try loading Spacy's small model `en_core_web_sm` as below:"],"metadata":{"id":"-kyXovd9UVuE"}},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"id":"h_SOdrciauJi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then let's build the `patterns` list with the labels we are interested in i.e. `PLNAME`, `GEONOUN` and `LOCADV`."],"metadata":{"id":"LLhvRhTPav90"}},{"cell_type":"code","source":["patterns = [{\"label\": \"PLNAME\", \"pattern\": plname}\n","            for plname in place_names\n","            ] + [{\"label\": \"GEONOUN\", \"pattern\": noun}\n","            for noun in geonouns\n","            ] + [{\"label\": \"LOCADV\", \"pattern\": adverb}\n","            for adverb in loc_advs]"],"metadata":{"id":"-7iUVB_CUHY5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, let's add the entity ruler with the patterns to the model's pipeline and visualise"],"metadata":{"id":"kr8SwXJxb5sG"}},{"cell_type":"code","source":["ruler = nlp.add_pipe(\"entity_ruler\")\n","ruler.add_patterns(patterns)"],"metadata":{"id":"577GF7OVUO-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc = nlp(example_text)\n","displacy.render(doc, style=\"ent\", jupyter=True, options=options)"],"metadata":{"id":"SvfsB7KcUqAr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Well, this doesn't look good 😞. \n","\n","However, if you look at the components in the models processing pipeline, it appears that the existing NER component overrode our rules.\n","```\n","['tok2vec','tagger','parser','attribute_ruler','lemmatizer', 'ner', 'entity_ruler']\n","```"],"metadata":{"id":"_nxUv6FTdCNH"}},{"cell_type":"code","source":["nlp.pipe_names"],"metadata":{"id":"_IvJ-E8xd4Lz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["So, let's remove the `entity_ruler` and add it *before* the `ner`..."],"metadata":{"id":"OsNQfaDPezM_"}},{"cell_type":"code","source":["nlp.remove_pipe(\"entity_ruler\")"],"metadata":{"id":"tG4CykNfgtAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n","ruler.add_patterns(patterns)"],"metadata":{"id":"n2V1-R4phGYZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then visualize..."],"metadata":{"id":"I_z-yy0yiSkC"}},{"cell_type":"code","source":["doc = nlp(example_text)\n","displacy.render(doc, style=\"ent\", jupyter=True, options=options)"],"metadata":{"id":"SvLHegpghQAe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is now better 🙂. Now we can extract matching patterns for place names, geo nouns and locative adverbs as well as other entities defined in the models `ner` component."],"metadata":{"id":"837U5LWeiYV5"}}]}